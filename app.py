import streamlit as st
import google.generativeai as genai
from PIL import Image
import io
import pkg_resources

# -----------------------------
# ê¸°ë³¸ ì„¤ì •
# -----------------------------
st.set_page_config(page_title="SDXL & Grok Prompt Extractor PRO", layout="centered")
st.title("ğŸ“¸ SDXL & Grok í”„ë¡¬í”„íŠ¸ ì¶”ì¶œê¸°v1")

st.write("SDK version:", pkg_resources.get_distribution("google-generativeai").version)

# -----------------------------
# API KEY ì„¤ì •
# -----------------------------
api_key = st.secrets.get("GEMINI_API_KEY")

if not api_key:
    api_key = st.sidebar.text_input("Gemini API Key ì…ë ¥", type="password")

if not api_key:
    st.warning("âš  Gemini API Keyë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    st.stop()

genai.configure(api_key=api_key)

# -----------------------------
# ëª¨ë¸ ê³ ì •
# -----------------------------
MODEL_NAME = "models/gemini-2.5-flash"
model = genai.GenerativeModel(MODEL_NAME)

st.success(f"í˜„ì¬ ì‚¬ìš© ëª¨ë¸: {MODEL_NAME}")

# -----------------------------
# ğŸ› Generation ì˜µì…˜
# -----------------------------
st.sidebar.header("ğŸ› í”„ë¡¬í”„íŠ¸ ê°•ë„ ì„¤ì •")

temperature = st.sidebar.slider("Temperature (ì°½ì˜ì„±)", 0.0, 1.5, 0.7, 0.1)
top_p = st.sidebar.slider("Top-P (í™•ë¥  ë‹¤ì–‘ì„±)", 0.1, 1.0, 0.9, 0.05)
top_k = st.sidebar.slider("Top-K (ë‹¨ì–´ í›„ë³´ ë²”ìœ„)", 1, 100, 40, 1)
max_tokens = st.sidebar.slider("Max Output Tokens (ê¸¸ì´)", 100, 2048, 800, 50)

generation_config = {
    "temperature": temperature,
    "top_p": top_p,
    "top_k": top_k,
    "max_output_tokens": max_tokens,
}

# -----------------------------
# ì´ë¯¸ì§€ ì—…ë¡œë“œ
# -----------------------------
uploaded_file = st.file_uploader(
    "ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”",
    type=["png", "jpg", "jpeg"]
)

if uploaded_file:
    image = Image.open(uploaded_file)
    st.image(image, use_container_width=True)

    img_byte_arr = io.BytesIO()
    image.save(img_byte_arr, format="PNG")
    img_bytes = img_byte_arr.getvalue()

    st.write("---")
    col1, col2 = st.columns(2)

    # ============================================================
    # ğŸš€ SDXL í”„ë¡¬í”„íŠ¸ + ë„¤ê±°í‹°ë¸Œ ìë™ ìƒì„±
    # ============================================================
    with col1:
        if st.button("ğŸš€ SDXL í”„ë¡¬í”„íŠ¸ ìƒì„±"):
            with st.spinner("SDXL ë¶„ì„ ì¤‘..."):
                try:
                    response = model.generate_content(
                        [
                            {
                                "role": "user",
                                "parts": [
                                    "Analyze this image for SDXL image generation.\n"
                                    "1. Generate a highly detailed positive prompt using comma-separated keywords.\n"
                                    "2. Generate a professional SDXL negative prompt.\n"
                                    "Format:\n"
                                    "Positive Prompt:\n"
                                    "...\n\n"
                                    "Negative Prompt:\n"
                                    "...",
                                    {"mime_type": "image/png", "data": img_bytes},
                                ],
                            }
                        ],
                        generation_config=generation_config
                    )

                    output_text = response.text

                    st.subheader("ğŸ¨ SDXL Prompt Result")
                    st.code(output_text)

                    # ğŸ“‹ ë³µì‚¬ ë²„íŠ¼
                    st.download_button(
                        label="ğŸ“‹ í”„ë¡¬í”„íŠ¸ ë³µì‚¬ (txt ë‹¤ìš´ë¡œë“œ)",
                        data=output_text,
                        file_name="sdxl_prompt.txt",
                        mime="text/plain"
                    )

                    # ğŸ¯ í† í° ì‚¬ìš©ëŸ‰
                    if hasattr(response, "usage_metadata"):
                        usage = response.usage_metadata
                        st.info(
                            f"Prompt Tokens: {usage.prompt_token_count} | "
                            f"Output Tokens: {usage.candidates_token_count} | "
                            f"Total: {usage.total_token_count}"
                        )

                except Exception as e:
                    st.error(f"ì—ëŸ¬ ë°œìƒ: {e}")

    # ============================================================
    # ğŸ§  Grok í”„ë¡¬í”„íŠ¸ ìƒì„±
    # ============================================================
    with col2:
        if st.button("ğŸ§  Grok í”„ë¡¬í”„íŠ¸ ìƒì„±"):
            with st.spinner("Grok ìŠ¤íƒ€ì¼ ë¶„ì„ ì¤‘..."):
                try:
                    response = model.generate_content(
                        [
                            {
                                "role": "user",
                                "parts": [
                                    "Analyze this image and describe it in vivid, expressive natural English.\n"
                                    "Make it emotional, descriptive, and conversational.\n"
                                    "No bullet points.",
                                    {"mime_type": "image/png", "data": img_bytes},
                                ],
                            }
                        ],
                        generation_config=generation_config
                    )

                    output_text = response.text

                    st.subheader("ğŸ’¬ Grok Prompt")
                    st.code(output_text)

                    # ğŸ“‹ ë³µì‚¬ ë²„íŠ¼
                    st.download_button(
                        label="ğŸ“‹ í”„ë¡¬í”„íŠ¸ ë³µì‚¬ (txt ë‹¤ìš´ë¡œë“œ)",
                        data=output_text,
                        file_name="grok_prompt.txt",
                        mime="text/plain"
                    )

                    # ğŸ¯ í† í° ì‚¬ìš©ëŸ‰
                    if hasattr(response, "usage_metadata"):
                        usage = response.usage_metadata
                        st.info(
                            f"Prompt Tokens: {usage.prompt_token_count} | "
                            f"Output Tokens: {usage.candidates_token_count} | "
                            f"Total: {usage.total_token_count}"
                        )

                except Exception as e:
                    st.error(f"ì—ëŸ¬ ë°œìƒ: {e}")
